## Application 3 {.smaller}


::: {.panel-tabset}

## {{< fa brands github >}}

:::{.callout-tip .nonincremental collapse="true" icon=false}
# Partie 0 : préparation

* Remplacer le contenu du script `get_data.R` en copiant-collant le contenu de [ce fichier](https://raw.githubusercontent.com/InseeFrLab/formation-bonnes-pratiques-git-R/refs/heads/main/R/checkpoints/application3/get_data.R). Exécuter ce script, il importe les fichiers nécessaires pour cette application.
* Créer un script `benchmark_parquet.R` afin de réaliser les comparaisons de performance des parties suivantes de l'application

:::

## {{< fa brands gitlab >}} insee

:::{.callout-tip .nonincremental collapse="true" icon=false}
# Partie 0 : préparation

* Remplacer le contenu du script `get_data_ls3.R` en copiant-collant le contenu de [ce fichier](https://raw.githubusercontent.com/InseeFrLab/formation-bonnes-pratiques-git-R/refs/heads/main/R/checkpoints/application3/get_data_ls3.R). Exécuter ce script, il importe les fichiers nécessaires pour cette application.
* Créer un script `benchmark_parquet.R` afin de réaliser les comparaisons de performance des parties suivantes de l'application

:::

:::



## Application 3 {.smaller}

:::{.callout-tip .nonincremental collapse="true" icon=false}
# Partie 1 : Du `CSV` au `Parquet`

Tout au long de cette application, nous allons voir comment utiliser le format `Parquet` de manière la plus efficiente. Afin de comparer les différents formats et méthodes d'utilisation, nous allons **comparer le temps d'exécution et l'usage mémoire d'une requête standard**. Commençons par comparer les formats `CSV` et `Parquet`.

* Remplacer le contenu du script `get_data.R` en copiant-collant le contenu de [ce fichier](https://raw.githubusercontent.com/InseeFrLab/formation-bonnes-pratiques-git-R/refs/heads/main/R/checkpoints/application3/get_data.R). Exécuter ce script, il importe les fichiers nécessaires dans cette application
* Pour effectuer les comparaisons de performance, on va utiliser la fonction [bench::mark](https://bench.r-lib.org/#benchmark). Analyser la documentation pour comprendre ce que la fonction attend en entrée. 
* La requête suivante permet de calculer les données pour construire une pyramide des âges sur un département donné, à partir du fichier `CSV` du recensement. Encapsuler la requête dans une fonction `req_csv` (sans argument).

```{.r}
res <- readr::read_csv("data/RPindividus_24.csv") %>% 
    filter(DEPT == "36") %>%
    group_by(AGED, DEPT) %>%
    summarise(n_indiv = sum(IPONDI))
```

* Sur le même modèle, construire une fonction `req_read_parquet` basée cette fois sur le fichier `data/RPindividus_24.parquet` chargé avec la fonction [read_parquet](https://arrow.apache.org/docs/r/reference/read_parquet.html) d'`Arrow`
* Comparer les performances (temps d'exécution et allocation mémoire) de ces deux méthodes grâce à la fonction [bench::mark](https://bench.r-lib.org/#benchmark), à laquelle on passera les paramètres `iterations = 1` (comparaison à partir d'une seule itération) et `check = FALSE` (autorise les outputs des deux fonctions à être différents).

:::

_❓️ Quelle semble être la limite de la fonction `read_parquet` ?_

## Application 3 {.smaller}

::: {.callout-tip .nonincremental collapse="true" icon=false}
## Partie 2 : Exploiter la *lazy evaluation* et les optimisations d'`Arrow`

La partie précédente a montré un **gain de temps considérable** du passage de `CSV` à `Parquet`. Néanmoins, l'**utilisation mémoire était encore très élevée** alors qu'on utilise de fait qu'une infime partie du fichier. Dans cette partie, on va voir comment utiliser la ***lazy evaluation*** et les **optimisations du plan d'exécution** effectuées par `Arrow` pour exploiter pleinement la puissance du format `Parquet`.

* Utiliser la fonction [arrow::open_dataset](https://arrow.apache.org/docs/r/reference/open_dataset.html) pour ouvrir le fichier `data/RPindividus_24.parquet`. Regarder la classe de l'objet obtenu.
* Afficher les 5 premières lignes de la table avec la fonction `head()`. Observer l'objet obtenu (sortie en console, classe).
* Ajouter une étape `collect()` à la fin de cette chaîne. Comprenez-vous la différence ?
* Construire une fonction `req_open_dataset` sur le modèle de celles de la partie précédente, qui importe cette fois les données avec la fonction [arrow::open_dataset](https://arrow.apache.org/docs/r/reference/open_dataset.html)
* Comparer les performances (temps d'exécution et allocation mémoire) des trois méthodes (`CSV`, `read_parquet` et `open_dataset`) grâce à la fonction [bench::mark](https://bench.r-lib.org/#benchmark)

:::

_❓️ Quelle méthode retenir pour lire un `Parquet` avec `Arrow` ?_

## Application 3 {.smaller}

::: {.callout-tip .nonincremental collapse="true" icon=false}
# Partie 3 : Le `Parquet` partitionné

La *lazy evaluation* et les optimisations d'`Arrow` apportent des gain de performance considérables. Mais on peut encore faire mieux ! Lorsqu'on sait qu'on va être amené à **filter régulièrement les données selon une variable d'intérêt**, on a tout intérêt à **partitionner** le fichier `Parquet` selon cette variable.

* Parcourir la documentation de la fonction [arrow::write_dataset](https://arrow.apache.org/docs/r/reference/write_dataset.html) pour comprendre comment spécifier la clé de partitionnement d'un fichier `Parquet`. Plusieurs méthodes sont possibles !
* Dans une même chaîne, importer la table individus complète du recensement `data/RPindividus.parquet` avec la fonction [arrow::open_dataset](https://arrow.apache.org/docs/r/reference/open_dataset.html) et l'exporter en une table `data/RPindividus_partitionne.parquet` partitionnée par la région (`REGION`) et le département (`DEPT`)
* Observer l'arborescence de fichiers de la table exportée
* Modifier la fonction `req_open_dataset` de la partie précédente pour partir de la table complète (non-partitionnée) `data/RPindividus.parquet` au lieu de l'échantillon
* Construire une fonction `req_open_dataset_partitionne` sur le modèle de `req_open_dataset`, qui importe cette fois les données partitionnées `data/RPindividus_dept.parquet`. Ne pas oublier de spécifier le paramètre `hive_style = TRUE`.
* Comparer les performances (temps d'exécution et allocation mémoire) des deux méthodes grâce à la fonction [bench::mark](https://bench.r-lib.org/#benchmark)

:::

::: {.nonincremental}

_❓️ Dans le cadre d'une mise à disposition de données en `Parquet` :_

* _Comment bien choisir la/les clé(s) de partitionnement ?_
* _Quelle est la limite à garder en tête ?_

:::


## Application 3 {.smaller}

:::{.callout-tip .nonincremental collapse="true" icon=false}
# Partie 4 : mise à jour de la chaîne de production

Convaincus par ce comparatif, nous allons maintenant mettre à jour le format des données utilisées pour notre chaîne de production.

* Modifier le script `script.R` pour importer les données d'entrée de votre chaîne à partir de la table `Parquet` partitionnée par département
* Vérifier que le code tourne de A à Z et l'adapter si ce n'est pas le cas
*

:::

_❓️ Cette mise à jour des données utilisées en source de la chaîne de production vous semble-t-elle complexe ? Pourquoi ?_


## Checkpoint

::: {.callout-caution .noincremental}
## Checkpoint

* Le script [`benchmark_parquet.R`](https://raw.githubusercontent.com/InseeFrLab/formation-bonnes-pratiques-git-R/refs/heads/main/R/checkpoints/application3/benchmark_parquet.R)
* Le script [`script.R`](https://raw.githubusercontent.com/InseeFrLab/formation-bonnes-pratiques-git-R/refs/heads/main/R/checkpoints/application3/script.R)

![](checkpoint.jpg){width=40% fig-align="center"}

:::
