## Application 3 (pr√©paration) {.smaller}

:::{.callout-tip .nonincremental collapse="true" icon=false}
# Partie 0: pr√©paration de l'exercice
* Remplacer le contenu du script `R/get_data.R` en copiant-collant le contenu de [ce fichier](https://raw.githubusercontent.com/InseeFrLab/formation-bonnes-pratiques-git-R/refs/heads/main/R/checkpoints/application3/get_data.R). Ex√©cuter ce script, il cr√©e les fichiers n√©cessaires pour ces exercices.
* Cr√©er le script `R/benchmarking_functions.R` en copiant-collant le contenu de [ce fichier](https://raw.githubusercontent.com/InseeFrLab/formation-bonnes-pratiques-git-R/refs/heads/main/R/checkpoints/application3/benchmark_functions.R)
* Cr√©er un nouveau script `R` qui servira de bac √† sable pour tester le format `Parquet`.
* Cr√©er les variables qui seront utiles pour les prochaines questions

```{.r}
columns_subset <- c(
  "REGION", "AGED", "ANAI", "CATL", "COUPLE",
  "SEXE", "SURF", "TP", "TRANS"
)

filename_sample_csv <- "data/RPindividus_24.csv"
filename_sample_parquet <- gsub("csv", "parquet", filename_sample_csv)
filename_full_parquet <- gsub("_24", "", filename_sample_parquet)
filename_full_csv <- gsub("parquet", "csv", filename_full_parquet)
```

:::

## Application 3 (partie 1) {.smaller}

::: {.callout-tip .nonincremental collapse="true" icon=false}
## Partie 1: Ouvrir un fichier `Parquet` et comprendre la logique de la lecture par bloc

Lecture du fichier avec `read_parquet` du _package_ `arrow`:

* Lire les donn√©es dont le chemin est stock√© dans `filename_sample_parquet`. Pour mesurer le temps d'ex√©cution, vous pouvez utiliser le squelette de code sugg√©r√© ci-dessous üëáÔ∏è.
* Faire la m√™me chose mais cette fois, ajouter un filtre _ex post_ avec les colonnes (`select(any_of(columns_subset))`). Mesurez-vous une diff√©rence dans les temps de traitement ?

Lecture du fichier avec `open_dataset` du _package_ `arrow`:

* Cette fois, lire le fichier avec `open_dataset(filename_sample_parquet)`. Regarder la classe de cet objet. 
* Faire un `head(5)` apr√®s `open_dataset`. Observer l'objet obtenu (sortie en console, classe).
* Maintenant regarder lorsque vous ajouter `collect()` apr√®s cette cha√Æne.
* Mesurer le temps d'ex√©cution de `open_dataset(filename_sample_parquet) %>% collect()`. Ajouter le filtre `select(any_of(columns_subset))`. Sa place influence-t-elle la vitesse de votre processus ? 

Comparaison √† la lecture d'un CSV: 

* Utiliser `readr::read_csv` pour lire le fichier (chemin `filename_sample_csv`) avec et sans l'argument `col_select`. Avez-vous des gains de performance si vous ne lisez le fichier qu'avec ces colonnes ? 

<details>

<summary>
Mesurer le temps d'ex√©cution
</summary>

```{.r}
start_time <- Sys.time()
# lecture du fichier ici
end_time <- Sys.time()
diff_time <- end_time - start_time
```

</details>

:::

_‚ùìÔ∏è Quelle m√©thode retenir pour lire un `Parquet` avec `Arrow` ?_

## Application 3 (partie 2) {.smaller}

::: {.callout-tip .nonincremental collapse="true" icon=false}
## Partie 2: Un format l√©ger et efficace

Dans cet exercice, vous devrez utiliser `open_dataset` pour lire les `Parquet`. 

* Observer l'espace disque de chaque fichier par le biais de l'explorateur de fichiers
* Mesurer le temps d'ex√©cution de la lecture du fichier dont le chemin est stock√© dans la variable `filename_full_parquet`. 
    + Faire ceci avec et sans le filtre des colonnes[^csv].
    + La croissance du temps de traitement vous appara√Æt-elle √©norme ? 
* Ajouter apr√®s cette √©tape de lecture `filter(REGION == 24)`. Comprenez-vous pourquoi vous ne b√©n√©ficiez pas de gain de performance ?   

:::

_‚ùìÔ∏è Dans quel ordre sont faits les filtres par `Arrow` ?_

[^csv]: Ne pas faire ceci maintenant avec le CSV, le _benchmark_ arrive prochainement.

## Application 3 (partie 3) {.smaller}

::: {.callout-tip .nonincremental collapse="true" icon=false}
# Partie 3: le Parquet partitionn√©

* Utiliser le code ci-dessous pour partitionner le fichier `Parquet` par _"REGION"_ et _"DEPT"_

```{.r}
open_dataset(filename_full_parquet) %>%
  group_by(REGION, DEPT) %>%
  write_dataset("./data/RPindividus")
```

* Observer l'arborescence de fichiers
* Utiliser `Arrow` pour lire les donn√©es de la Corse du Sud (code r√©gion 94, code d√©partement 2A) √† partir de ce fichier partitionn√©

:::

::: {.nonincremental}

_‚ùìÔ∏è Imaginons que les utilisateurs voudraient aussi se restreindre √† certains types de m√©nages en fonction de caract√©ristiques:_

* _Que faudrait-il faire ?_
* _Quelle est la limite ?_

:::

## Application 3 (partie 3) {.smaller}

Quand on g√©n√©ralise cette d√©marche de _benchmark_, on obtient le tableau de performance suivant

![](img/tableau-perf-parquet.png){fig-align="center"}


## Application 3 (partie 4) {.smaller}

:::{.callout-tip .nonincremental collapse="true" icon=false}
# Partie 4: mise √† jour de la cha√Æne de production

Nous allons mettre √† jour les donn√©es utilis√©es pour notre cha√Æne de production:

* Lire les donn√©es √† partir du morceau de code propos√©
* V√©rifier que le code tourne de A √† Z et changer celui-ci marginalement si ce n'est pas le cas

<details>

<summary>
Modification du code pour l'import de donn√©es
</summary>

```{.r}
columns_subset <- c(
  "REGION", "AGED", "ANAI", "CATL", "COUPLE",
  "SEXE", "SURF", "TP", "TRANS", "IPONDI"
)

df <- open_dataset(
  "./data/RPindividus",
  hive_style = TRUE
) %>%
  filter(REGION == 24) %>%
  select(any_of(columns_subset)) %>%
  collect()

```

</details>


:::



_‚ùìÔ∏è Cette mise √† jour des donn√©es utilis√©es vous est-elle apparue plus simple que les changements de l'application 1 ?_


## Checkpoint

::: {.callout-caution .noincremental}
## Checkpoint

* Le script [`main.R`](https://raw.githubusercontent.com/InseeFrLab/formation-bonnes-pratiques-git-R/refs/heads/main/R/checkpoints/application3/main.R)
* Le script [`R/functions.R`](https://raw.githubusercontent.com/InseeFrLab/formation-bonnes-pratiques-git-R/refs/heads/main/R/checkpoints/application3/functions.R)


![](checkpoint.jpg){width="40%"}{fig-align="center"}

:::
