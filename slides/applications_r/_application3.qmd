## Application 3 (pr√©paration) {.smaller}


::: {.panel-tabset}

## {{< fa brands github >}}

:::{.callout-tip .nonincremental collapse="true" icon=false}
# Partie 1 : du `CSV` au `Parquet`

Tout au long de cette application, nous allons voir comment utiliser le format `Parquet` de mani√®re la plus efficiente. Afin de comparer les diff√©rents formats et m√©thodes d'utilisation, nous allons comparer le temps d'ex√©cution et l'usage m√©moire d'une requ√™te standard. Commen√ßons par comparer les formats `CSV` et `Parquet`.

* Remplacer le contenu du script `get_data.R` en copiant-collant le contenu de [ce fichier](https://raw.githubusercontent.com/InseeFrLab/formation-bonnes-pratiques-git-R/refs/heads/main/R/checkpoints/application3/get_data.R). Ex√©cuter ce script, il importe les fichiers n√©cessaires dans cette application
* Pour effectuer les comparaisons de performance, on va utiliser la fonction [bench::mark](https://bench.r-lib.org/#benchmark). Analyser la documentation pour comprendre ce que la fonction attend en entr√©e. 
* La requ√™te suivante permet de calculer les donn√©es pour construire une pyramide des √¢ges sur un d√©partement donn√©, √† partir du fichier `CSV` du recensement. Encapsuler la requ√™te dans une fonction `req_csv` (sans argument).

```{.r}
res <- readr::read_csv("data/RPindividus_24.csv") %>% 
    filter(DEPT == "36") %>%
    group_by(AGED, DEPT) %>%
    summarise(n_indiv = sum(IPONDI))
```

* Sur le m√™me mod√®le, construire une fonction `req_read_parquet` bas√©e cette fois sur le fichier `data/RPindividus_24.parquet` charg√© avec la fonction [read_parquet](https://arrow.apache.org/docs/r/reference/read_parquet.html) d'`Arrow`
* Comparer les performances (temps d'ex√©cution et allocation m√©moire) de ces deux m√©thodes gr√¢ce √† la [bench::mark](https://bench.r-lib.org/#benchmark), √† laquelle on passera les param√®tres `iterations = 1` (comparaison √† partir d'une seule it√©ration) et `check = FALSE` (autorise les outputs des deux fonctions √† √™tre diff√©rents).

:::

## {{< fa brands gitlab >}} insee

:::{.callout-tip .nonincremental collapse="true" icon=false}
# Partie 1 : du `CSV` au `Parquet`

Tout au long de cette application, nous allons voir comment utiliser le format `Parquet` de mani√®re la plus efficiente. Afin de comparer les diff√©rents formats et m√©thodes d'utilisation, nous allons comparer le temps d'ex√©cution et l'usage m√©moire d'une requ√™te standard. Commen√ßons par comparer les formats `CSV` et `Parquet`.

* Remplacer le contenu du script `get_data_ls3.R` en copiant-collant le contenu de [ce fichier](https://raw.githubusercontent.com/InseeFrLab/formation-bonnes-pratiques-git-R/refs/heads/main/R/checkpoints/application3/get_data_ls3.R). Ex√©cuter ce script, il importe les fichiers n√©cessaires dans cette application
* Pour effectuer les comparaisons de performance, on va utiliser la fonction [bench::mark](https://bench.r-lib.org/#benchmark). Analyser la documentation pour comprendre ce que la fonction attend en entr√©e. 
* La requ√™te suivante permet de calculer les donn√©es pour construire une pyramide des √¢ges sur un d√©partement donn√©, √† partir du fichier `CSV` du recensement. Encapsuler la requ√™te dans une fonction `req_csv` (sans argument).

```{.r}
res <- readr::read_csv("data/RPindividus_24.csv") %>% 
    filter(DEPT == "36") %>%
    group_by(AGED, DEPT) %>%
    summarise(n_indiv = sum(IPONDI))
```

* Sur le m√™me mod√®le, construire une fonction `req_read_parquet` bas√©e cette fois sur le fichier `data/RPindividus_24.parquet` charg√© avec la fonction [read_parquet](https://arrow.apache.org/docs/r/reference/read_parquet.html) d'`Arrow`
* Comparer les performances (temps d'ex√©cution et allocation m√©moire) de ces deux m√©thodes gr√¢ce √† la [bench::mark](https://bench.r-lib.org/#benchmark), √† laquelle on passera les param√®tres `iterations = 1` (comparaison √† partir d'une seule it√©ration) et `check = FALSE` (autorise les outputs des deux fonctions √† √™tre diff√©rents).
:::

:::


## Application 3 (partie 1) {.smaller}

::: {.callout-tip .nonincremental collapse="true" icon=false}
## Partie 1 : Ouvrir un fichier `Parquet` et comprendre la logique de la lecture par bloc

Lecture du fichier avec `read_parquet` du _package_ `arrow` :

* Lire les donn√©es dont le chemin est stock√© dans `filename_sample_parquet`. Pour mesurer le temps d'ex√©cution, vous pouvez utiliser le squelette de code sugg√©r√© ci-dessous üëáÔ∏è.
* Faire la m√™me chose mais cette fois, ajouter un filtre _ex post_ avec les colonnes (`select(any_of(columns_subset))`). Mesurez-vous une diff√©rence dans les temps de traitement ?

Lecture du fichier avec `open_dataset` du _package_ `arrow` :

* Cette fois, lire le fichier avec `open_dataset(filename_sample_parquet)`. Regarder la classe de cet objet. 
* Faire un `head(5)` apr√®s `open_dataset`. Observer l'objet obtenu (sortie en console, classe).
* Maintenant regarder lorsque vous ajouter `collect()` apr√®s cette cha√Æne.
* Mesurer le temps d'ex√©cution de `open_dataset(filename_sample_parquet) %>% collect()`. Ajouter le filtre `select(any_of(columns_subset))`. Sa place influence-t-elle la vitesse de votre processus ? 

Comparaison √† la lecture d'un CSV : 

* Utiliser `readr::read_csv` pour lire le fichier (chemin `filename_sample_csv`) avec et sans l'argument `col_select`. Avez-vous des gains de performance si vous ne lisez le fichier qu'avec ces colonnes ? 

<details>

<summary>
Mesurer le temps d'ex√©cution
</summary>

```{.r}
start_time <- Sys.time()
# lecture du fichier ici
end_time <- Sys.time()
diff_time <- end_time - start_time
```

</details>

:::

_‚ùìÔ∏è Quelle m√©thode retenir pour lire un `Parquet` avec `Arrow` ?_

## Application 3 (partie 2) {.smaller}

::: {.callout-tip .nonincremental collapse="true" icon=false}
## Partie 2 : Un format l√©ger et efficace

Dans cet exercice, vous devrez utiliser `open_dataset` pour lire les `Parquet`. 

* Observer l'espace disque de chaque fichier par le biais de l'explorateur de fichiers
* Mesurer le temps d'ex√©cution de la lecture du fichier dont le chemin est stock√© dans la variable `filename_full_parquet`. 
    + Faire ceci avec et sans le filtre des colonnes[^csv].
    + La croissance du temps de traitement vous appara√Æt-elle √©norme ? 
* Ajouter apr√®s cette √©tape de lecture `filter(REGION == 24)`. Comprenez-vous pourquoi vous ne b√©n√©ficiez pas de gain de performance ?   

:::

_‚ùìÔ∏è Dans quel ordre sont faits les filtres par `Arrow` ?_

[^csv]: Ne pas faire ceci maintenant avec le CSV, le _benchmark_ arrive prochainement.

## Application 3 (partie 3) {.smaller}

::: {.callout-tip .nonincremental collapse="true" icon=false}
# Partie 3 : le Parquet partitionn√©

* Utiliser le code ci-dessous pour partitionner le fichier `Parquet` par _"REGION"_ et _"DEPT"_

```{.r}
open_dataset(filename_full_parquet) %>%
  group_by(REGION, DEPT) %>%
  write_dataset("./data/RPindividus")
```

* Observer l'arborescence de fichiers
* Utiliser `Arrow` pour lire les donn√©es de la Corse du Sud (code r√©gion 94, code d√©partement 2A) √† partir de ce fichier partitionn√©

:::

::: {.nonincremental}

_‚ùìÔ∏è Imaginons que les utilisateurs voudraient aussi se restreindre √† certains types de m√©nages en fonction de caract√©ristiques :_

* _Que faudrait-il faire ?_
* _Quelle est la limite ?_

:::


## Application 3 (partie 4) {.smaller}

:::{.callout-tip .nonincremental collapse="true" icon=false}
# Partie 4 : mise √† jour de la cha√Æne de production

Nous allons mettre √† jour les donn√©es utilis√©es pour notre cha√Æne de production:

* Lire les donn√©es √† partir du morceau de code propos√©
* V√©rifier que le code tourne de A √† Z et changer celui-ci marginalement si ce n'est pas le cas

<details>

<summary>
Modification du code pour l'import de donn√©es
</summary>

```{.r}
columns_subset <- c(
  "REGION", "AGED", "ANAI", "CATL", "COUPLE",
  "SEXE", "SURF", "TP", "TRANS", "IPONDI"
)

df <- open_dataset(
  "./data/RPindividus",
  hive_style = TRUE
) %>%
  filter(REGION == 24) %>%
  select(any_of(columns_subset)) %>%
  collect()

```

</details>


:::



_‚ùìÔ∏è Cette mise √† jour des donn√©es utilis√©es vous est-elle apparue plus simple que les changements de l'application 1 ?_


## Checkpoint

::: {.callout-caution .noincremental}
## Checkpoint

* Le script [`main.R`](https://raw.githubusercontent.com/InseeFrLab/formation-bonnes-pratiques-git-R/refs/heads/main/R/checkpoints/application3/main.R)
* Le script [`R/functions.R`](https://raw.githubusercontent.com/InseeFrLab/formation-bonnes-pratiques-git-R/refs/heads/main/R/checkpoints/application3/functions.R)


![](checkpoint.jpg){width=40% fig-align="center"}

:::
